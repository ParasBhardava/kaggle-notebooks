{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**3. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this notebook, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:22:23.903264Z","iopub.execute_input":"2025-11-11T10:22:23.904042Z","iopub.status.idle":"2025-11-11T10:22:23.985316Z","shell.execute_reply.started":"2025-11-11T10:22:23.904016Z","shell.execute_reply":"2025-11-11T10:22:23.984502Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:22:27.105537Z","iopub.execute_input":"2025-11-11T10:22:27.106275Z","iopub.status.idle":"2025-11-11T10:23:12.835995Z","shell.execute_reply.started":"2025-11-11T10:22:27.106245Z","shell.execute_reply":"2025-11-11T10:23:12.834555Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:24:44.611167Z","iopub.execute_input":"2025-11-11T10:24:44.612756Z","iopub.status.idle":"2025-11-11T10:24:44.618176Z","shell.execute_reply.started":"2025-11-11T10:24:44.612722Z","shell.execute_reply":"2025-11-11T10:24:44.617247Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:24:51.168817Z","iopub.execute_input":"2025-11-11T10:24:51.169575Z","iopub.status.idle":"2025-11-11T10:24:51.175709Z","shell.execute_reply.started":"2025-11-11T10:24:51.169540Z","shell.execute_reply":"2025-11-11T10:24:51.174750Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:24:53.721646Z","iopub.execute_input":"2025-11-11T10:24:53.721974Z","iopub.status.idle":"2025-11-11T10:24:53.728665Z","shell.execute_reply.started":"2025-11-11T10:24:53.721951Z","shell.execute_reply":"2025-11-11T10:24:53.727484Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:24:56.989448Z","iopub.execute_input":"2025-11-11T10:24:56.989758Z","iopub.status.idle":"2025-11-11T10:24:56.996312Z","shell.execute_reply.started":"2025-11-11T10:24:56.989727Z","shell.execute_reply":"2025-11-11T10:24:56.995223Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail in another notebook.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:05.320238Z","iopub.execute_input":"2025-11-11T10:25:05.320619Z","iopub.status.idle":"2025-11-11T10:25:15.027627Z","shell.execute_reply.started":"2025-11-11T10:25:05.320593Z","shell.execute_reply":"2025-11-11T10:25:15.026732Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are set to revolutionize AI by enabling \"Quantum AI.\" This involves using qubits, which can exist in multiple states simultaneously, to process vast amounts of information and explore numerous solutions at once, overcoming the limitations of classical computers.\n\nKey implications for AI include:\n\n*   **Enhanced Performance and Speed:** Quantum machine learning algorithms can drastically speed up AI model training and adaptation.\n*   **Solving Intractable Problems:** AI can tackle complex optimization, simulation, and modeling tasks previously deemed impossible.\n*   **Improved Data Processing:** Quantum systems promise more efficient handling and classification of large datasets.\n*   **Energy Efficiency:** Quantum computing offers a more sustainable approach to AI development.\n*   **Domain-Specific Breakthroughs:** Advancements are expected in Natural Language Processing, healthcare (drug discovery, personalized medicine), finance (risk analysis, modeling), and autonomous vehicles.\n\nWhile still in its early stages, the fusion of quantum computing and AI is anticipated to bring transformative breakthroughs in the coming decade, although widespread commercial use may be more than ten years away.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:23.468446Z","iopub.execute_input":"2025-11-11T10:25:23.468779Z","iopub.status.idle":"2025-11-11T10:25:23.474823Z","shell.execute_reply.started":"2025-11-11T10:25:23.468754Z","shell.execute_reply":"2025-11-11T10:25:23.473608Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:26.857152Z","iopub.execute_input":"2025-11-11T10:25:26.857460Z","iopub.status.idle":"2025-11-11T10:25:26.863428Z","shell.execute_reply.started":"2025-11-11T10:25:26.857430Z","shell.execute_reply":"2025-11-11T10:25:26.862455Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:29.195059Z","iopub.execute_input":"2025-11-11T10:25:29.195401Z","iopub.status.idle":"2025-11-11T10:25:29.201434Z","shell.execute_reply.started":"2025-11-11T10:25:29.195379Z","shell.execute_reply":"2025-11-11T10:25:29.200306Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:33.992593Z","iopub.execute_input":"2025-11-11T10:25:33.993444Z","iopub.status.idle":"2025-11-11T10:25:33.998592Z","shell.execute_reply.started":"2025-11-11T10:25:33.993415Z","shell.execute_reply":"2025-11-11T10:25:33.997691Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:36.754500Z","iopub.execute_input":"2025-11-11T10:25:36.754871Z","iopub.status.idle":"2025-11-11T10:25:44.953669Z","shell.execute_reply.started":"2025-11-11T10:25:36.754847Z","shell.execute_reply":"2025-11-11T10:25:44.952600Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Okay, I am OutlineAgent. I will generate a blog outline about the benefits of multi-agent systems for software developers.\n\nHere is the outline:\n\n## Headline: Supercharge Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\n### Introduction Hook:\nEver feel like your software projects are bogged down by complexity, slow development cycles, or missed deadlines? What if there was a way to break down daunting tasks, foster intelligent collaboration, and build more robust, adaptable systems? Enter multi-agent systems (MAS) ‚Äì a paradigm shift that's not just for AI researchers anymore, but a powerful toolkit for every software developer.\n\n### Main Sections:\n\n#### 1. Breaking Down the Monolith: Enhanced Modularity and Scalability\n*   **Decomposition of Complex Problems:** MAS allows developers to break down large, intricate problems into smaller, manageable sub-problems, each handled by an independent agent. This makes code easier to understand, develop, and maintain.\n*   **Independent Development and Testing:** Teams can work on individual agents concurrently without significant interdependencies, drastically speeding up development cycles and simplifying testing efforts.\n*   **Natural Scalability:** As your application needs grow, you can scale specific agents or add new ones to handle increased load or new functionalities, offering a more granular and efficient scaling strategy than traditional monolithic approaches.\n\n#### 2. Smarter Collaboration and Resource Management\n*   **Intelligent Task Allocation:** Agents can negotiate, bid, and collaborate to determine the most efficient allocation of tasks and resources, mimicking human teamwork and optimizing performance.\n*   **Dynamic Adaptation and Resilience:** In the face of unexpected failures or changing environments, MAS allows agents to adapt their strategies, re-allocate tasks, and find alternative solutions, leading to more resilient and fault-tolerant software.\n*   **Decentralized Decision-Making:** Avoid single points of failure and bottlenecks by distributing decision-making authority across multiple agents, leading to more robust and responsive systems.\n\n#### 3. Building the Next Generation of Software: New Possibilities and Architectures\n*   **Agent-Based Simulation:** MAS provides a powerful framework for simulating complex real-world systems, from supply chains to traffic flow, enabling better understanding and prediction for software design.\n*   **Autonomous and Self-Improving Systems:** Develop software that can learn from its environment, adapt its behavior over time, and even improve its own performance without constant human intervention.\n*   **Foundation for Distributed and IoT Applications:** The inherent distributed nature of MAS makes it an ideal architecture for building complex, interconnected systems in the Internet of Things (IoT) and other distributed computing environments.\n\n### Concluding Thought:\nThe adoption of multi-agent systems represents a significant evolution in how we approach software development. By embracing this paradigm, developers can unlock new levels of productivity, build more intelligent and resilient applications, and pave the way for innovative solutions to the challenges of tomorrow. It's time to move beyond rigid structures and embrace the power of distributed intelligence.\nWriterAgent > ## Supercharge Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\nAre your software projects drowning in complexity? Do slow development cycles and missed deadlines feel like the norm? Imagine a world where daunting tasks become manageable, collaboration is intelligent, and your systems are inherently robust. This isn't science fiction; it's the promise of **Multi-Agent Systems (MAS)**, a powerful paradigm shift that's rapidly becoming an essential toolkit for modern software developers.\n\nMAS offers a revolutionary approach by breaking down monolithic challenges. Instead of a single, massive codebase, you can decompose complex problems into smaller, independent sub-problems, each handled by a dedicated agent. This enhances **modularity**, making your code easier to understand, develop, and maintain. Crucially, teams can work on individual agents concurrently, drastically **speeding up development and testing cycles**. As your application grows, MAS provides natural **scalability**, allowing you to add or scale specific agents precisely where needed, a far more efficient approach than traditional monolithic scaling.\n\nBeyond structure, MAS fosters **smarter collaboration and resource management**. Agents can intelligently negotiate and collaborate to optimize task allocation and resource usage, mirroring efficient human teamwork. This distributed intelligence leads to more **resilient and fault-tolerant software**, as agents can dynamically adapt to failures or changing environments, re-allocating tasks and finding alternative solutions. By decentralizing decision-making, MAS eliminates single points of failure and bottlenecks, resulting in more responsive systems.\n\nFurthermore, MAS opens doors to building the **next generation of software**. It provides a robust framework for agent-based simulations, enabling deeper understanding of complex real-world systems. Imagine developing truly **autonomous and self-improving systems** that learn and adapt. For the burgeoning fields of distributed computing and the Internet of Things (IoT), MAS's inherent distributed nature makes it an ideal foundation for interconnected applications.\n\nEmbracing Multi-Agent Systems is more than just adopting a new technology; it's an evolution in how we conceive and build software. It's time to move beyond rigid structures and harness the power of distributed intelligence to unlock new levels of productivity and create more innovative, resilient applications for the future.\nEditorAgent > ## Supercharge Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\nAre your software projects constantly battling complexity? Do slow development cycles and missed deadlines feel like an unavoidable part of the process? Imagine a reality where daunting tasks are easily broken down, collaboration is intelligent, and your systems are inherently robust. This isn't a distant dream; it's the tangible promise of **Multi-Agent Systems (MAS)**, a powerful paradigm shift that is rapidly establishing itself as an essential toolkit for modern software developers.\n\nMAS introduces a revolutionary approach by tackling monolithic challenges head-on. Instead of wrestling with a single, sprawling codebase, you can decompose complex problems into smaller, independent sub-problems. Each of these is then expertly handled by a dedicated agent. This fundamental shift dramatically enhances **modularity**, making your code significantly easier to understand, develop, and maintain. Critically, MAS empowers teams to work on individual agents concurrently, which drastically **speeds up development and testing cycles**. Furthermore, as your application grows, MAS offers natural **scalability**. You can add or scale specific agents precisely where they are needed, a far more efficient and agile approach than traditional monolithic scaling strategies.\n\nBeyond structural improvements, MAS fosters **smarter collaboration and more effective resource management**. Agents can intelligently negotiate and collaborate to optimize task allocation and resource utilization, mirroring the efficiency of well-coordinated human teams. This distributed intelligence leads directly to more **resilient and fault-tolerant software**. Agents can dynamically adapt to failures or changing environments, re-allocating tasks and discovering alternative solutions without human intervention. By decentralizing decision-making, MAS effectively eliminates single points of failure and critical bottlenecks, resulting in more responsive and dependable systems.\n\nMoreover, MAS unlocks the potential to build the **next generation of software**. It provides a robust framework for sophisticated agent-based simulations, enabling a deeper understanding of complex real-world systems. Imagine developing truly **autonomous and self-improving systems** that can learn from their environment and adapt their behavior over time. For the rapidly expanding fields of distributed computing and the Internet of Things (IoT), MAS's inherently distributed nature makes it an ideal foundation for building interconnected, intelligent applications.\n\nEmbracing Multi-Agent Systems is more than just adopting a new technology; it represents an evolution in how we conceive and construct software. It's time to move beyond rigid, monolithic structures and harness the power of distributed intelligence to unlock new levels of productivity and create more innovative, resilient applications for the future.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:04.249799Z","iopub.execute_input":"2025-11-11T10:26:04.250147Z","iopub.status.idle":"2025-11-11T10:26:04.255924Z","shell.execute_reply.started":"2025-11-11T10:26:04.250124Z","shell.execute_reply":"2025-11-11T10:26:04.255021Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:06.639409Z","iopub.execute_input":"2025-11-11T10:26:06.640043Z","iopub.status.idle":"2025-11-11T10:26:06.645815Z","shell.execute_reply.started":"2025-11-11T10:26:06.640015Z","shell.execute_reply":"2025-11-11T10:26:06.644860Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:09.204691Z","iopub.execute_input":"2025-11-11T10:26:09.205635Z","iopub.status.idle":"2025-11-11T10:26:09.211203Z","shell.execute_reply.started":"2025-11-11T10:26:09.205584Z","shell.execute_reply":"2025-11-11T10:26:09.210406Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:12.722483Z","iopub.execute_input":"2025-11-11T10:26:12.722795Z","iopub.status.idle":"2025-11-11T10:26:12.729444Z","shell.execute_reply.started":"2025-11-11T10:26:12.722772Z","shell.execute_reply":"2025-11-11T10:26:12.728224Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:16.299401Z","iopub.execute_input":"2025-11-11T10:26:16.299740Z","iopub.status.idle":"2025-11-11T10:26:16.305802Z","shell.execute_reply.started":"2025-11-11T10:26:16.299716Z","shell.execute_reply":"2025-11-11T10:26:16.304780Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:25.664876Z","iopub.execute_input":"2025-11-11T10:26:25.665590Z","iopub.status.idle":"2025-11-11T10:26:31.780682Z","shell.execute_reply.started":"2025-11-11T10:26:25.665565Z","shell.execute_reply":"2025-11-11T10:26:31.779868Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **AI/ML Trends: Key Developments, Companies, and Impact**\n\n**1. Generative AI Advancements:**\n   - **Development:** Generative AI (GenAI) is moving beyond text to create complex multimedia content like graphics, video, and music. Companies like Google (Imagen, Muse) and OpenAI (GPT models) are at the forefront.\n   - **Impact:** This revolutionizes creative industries, content generation, and personalized experiences.\n\n**2. Rise of AI Agents:**\n   - **Development:** AI agents capable of independent action and task management are emerging. Salesforce's Agentforce is an example, designed to handle business workflows autonomously.\n   - **Impact:** This promises increased productivity by automating routine tasks across various sectors, though human oversight remains crucial.\n\n**3. Explainable AI (XAI) and Ethical AI:**\n   - **Development:** Growing emphasis on transparency in AI decision-making to build trust and meet regulatory needs, especially in sensitive fields like healthcare and finance.\n   - **Impact:** XAI is crucial for widespread adoption in regulated industries, ensuring fairness, accountability, and compliance.\n\n**Companies Involved:** Major players include Google, OpenAI, Microsoft, Salesforce, Nvidia, and AMD, among others, driving innovation in hardware and software.\n\n**Broader Impact:** These trends are transforming healthcare (diagnostics, telemedicine), finance (risk assessment, fraud detection), and technology (AI-driven automation, cybersecurity), leading to increased efficiency and new business models. However, adoption can be inconsistent, with a growing need for AI literacy and navigating evolving regulations.\nFinanceResearcher > **Fintech Trends for 2025**\n\n**1. Emerging Payment Technologies:** The adoption of P2P bank payments and stablecoin usage is rapidly increasing, with FedNow accelerating real-time payment options. This trend is making once-niche payment models mainstream alternatives.\n\n**2. AI in Personal Finance:** The AI in fintech market is experiencing significant growth, projected to reach $76.2 billion by 2033. AI is revolutionizing personal finance through smart budgeting, expense tracking, personalized investment advice, and automated bill management.\n\n**3. Blockchain Integration:** Blockchain technology is moving towards mainstream adoption, with TradFi embracing DeFi for faster, more secure, and transparent transactions. By 2027, 10% of global GDP could be tokenized on blockchain.\n\n**Market Implications:** These trends indicate a shift towards more efficient, personalized, and secure financial services. Increased adoption of new payment methods and AI-driven tools will likely enhance customer experience and operational efficiency for financial institutions. The integration of blockchain promises greater transparency and security in transactions.\n\n**Future Outlook:** Fintech is expected to continue its rapid growth, driven by technological advancements, evolving regulations, and increasing consumer demand for digital financial solutions. The market will likely see further innovation, leading to more accessible and integrated financial services globally.\nHealthResearcher > Here's a briefing on recent breakthroughs in Tech, Health, and Finance:\n\n**Health:**\n*   **mRNA Vaccine Technology:** Building on the success of COVID-19 vaccines, mRNA technology is being explored for numerous other diseases, promising faster development and adaptable platforms.\n*   **AI-driven Sepsis Detection:** Artificial intelligence can now detect sepsis hours earlier than traditional methods, significantly reducing mortality rates.\n*   **Diabetes Delay Medication:** Teplizumab, an FDA-approved drug, can delay the onset of Type 1 diabetes by an average of two years.\n    *   **Timeline:** These advances are largely available now or in late-stage development, with wider implementation expected within the next 1-5 years.\n\n**Technology:**\n*   **Quantum Computing:** Significant progress is being made towards making quantum computing practical for fields like drug discovery and cryptography.\n*   **Agentic AI:** AI systems are becoming more autonomous and capable of complex tasks, leading to new human-machine collaboration models and integration into specialized industries.\n*   **Brain-Computer Interfaces (BCIs):** Development continues on BCIs, aiming to restore function for individuals with paralysis and potentially enhance cognitive abilities in the future.\n    *   **Timeline:** Quantum computing's broad practical applications are anticipated within 5-10 years. Agentic AI is seeing rapid integration now, with deeper specialization in the next 2-5 years. BCIs are in early-stage development, with significant clinical applications within 5-10 years and broader enhancements further out.\n\n**Finance:**\n*   **AI and Machine Learning in Risk Decisioning:** AI/ML are increasingly used for sophisticated risk assessment and personalized financial advice.\n*   **Blockchain Beyond Cryptocurrency:** Blockchain is being explored for supply chain management, voting systems, and digital identity, offering enhanced transparency and security.\n*   **Central Bank Digital Currencies (CBDCs):** Central banks globally are exploring and developing digital forms of their currencies, potentially altering payment systems.\n    *   **Timeline:** AI/ML applications are widely implemented now. Blockchain's adoption is ongoing, with significant expansion expected in the next 3-7 years. CBDCs are in development and pilot phases, with widespread adoption timelines varying by region.\nAggregatorAgent > ## Executive Summary: Tech, Health, and Finance Briefing\n\nArtificial intelligence (AI) is the unifying force across all three sectors, driving unprecedented advancements. In technology, Generative AI is expanding multimedia creation, while AI agents are automating complex tasks. This trend is mirrored in finance with AI revolutionizing personal finance tools and risk assessment. Crucially, AI is also enhancing healthcare, enabling earlier sepsis detection and accelerating drug discovery, building on the success of mRNA vaccine technology.\n\nExplainable AI (XAI) and ethical considerations are paramount, especially as AI integration deepens in sensitive areas like healthcare and finance, demanding transparency and accountability.\n\nEmerging payment technologies, including P2P and stablecoins, are becoming mainstream in finance, facilitated by real-time payment options. Simultaneously, blockchain technology is maturing beyond cryptocurrency, promising increased transparency and security across supply chains and digital identity.\n\nOverall, these interconnected trends point towards a future of increased efficiency, personalization, and automation, while emphasizing the critical need for AI literacy and robust regulatory frameworks.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:45.007883Z","iopub.execute_input":"2025-11-11T10:26:45.008536Z","iopub.status.idle":"2025-11-11T10:26:45.013813Z","shell.execute_reply.started":"2025-11-11T10:26:45.008493Z","shell.execute_reply":"2025-11-11T10:26:45.012757Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:47.341749Z","iopub.execute_input":"2025-11-11T10:26:47.342100Z","iopub.status.idle":"2025-11-11T10:26:47.348174Z","shell.execute_reply.started":"2025-11-11T10:26:47.342079Z","shell.execute_reply":"2025-11-11T10:26:47.347326Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:52.645265Z","iopub.execute_input":"2025-11-11T10:26:52.646356Z","iopub.status.idle":"2025-11-11T10:26:52.651883Z","shell.execute_reply.started":"2025-11-11T10:26:52.646323Z","shell.execute_reply":"2025-11-11T10:26:52.650710Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:55.637141Z","iopub.execute_input":"2025-11-11T10:26:55.637529Z","iopub.status.idle":"2025-11-11T10:26:55.644255Z","shell.execute_reply.started":"2025-11-11T10:26:55.637503Z","shell.execute_reply":"2025-11-11T10:26:55.643136Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:26:58.796789Z","iopub.execute_input":"2025-11-11T10:26:58.797168Z","iopub.status.idle":"2025-11-11T10:26:58.803402Z","shell.execute_reply.started":"2025-11-11T10:26:58.797145Z","shell.execute_reply":"2025-11-11T10:26:58.802294Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:27:02.380725Z","iopub.execute_input":"2025-11-11T10:27:02.381088Z","iopub.status.idle":"2025-11-11T10:27:09.968762Z","shell.execute_reply.started":"2025-11-11T10:27:02.381064Z","shell.execute_reply":"2025-11-11T10:27:09.967912Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias had manned the Saltwick Head lighthouse for thirty years, his life a predictable rhythm of polishing brass and tending the lamp. One stormy Tuesday, a particularly vicious wave crashed against the tower, rattling the very foundations. When the spray cleared, Elias saw it ‚Äì a rolled-up piece of parchment wedged in a crevice near the base.\n\nHe retrieved it, his gnarled fingers clumsy with anticipation. Unfurling the brittle material, he gasped. It wasn't parchment at all, but something impossibly smooth, cool to the touch. And it glowed. A faint, emerald light pulsed from the intricate, swirling lines that formed‚Ä¶ a map. Not of any coast Elias knew, but of stars. Stars that seemed to wink and shift before his very eyes.\nCriticAgent > This story has a compelling hook and sets up a fascinating mystery. However, it could benefit from a bit more development in a few areas.\n\nHere are a few actionable suggestions:\n\n1.  **Expand on Elias's reaction and internal thoughts:** While his anticipation is mentioned, we don't get much insight into *what* he's feeling beyond surprise and clumsiness. Is he a superstitious man? Does this discovery spark a long-dormant sense of adventure? Does he feel fear, wonder, or a combination? Delving into his internal monologue would deepen his character and the emotional impact of the discovery.\n2.  **Describe the map's appearance in more detail:** The \"intricate, swirling lines\" and \"winking and shifting stars\" are evocative, but more specific imagery could make the map even more wondrous. Are there celestial bodies that look familiar but are in impossible configurations? Does the emerald light form patterns or symbols? The more concrete the description, the more the reader can visualize this extraordinary object.\n3.  **Hint at the \"why\" or \"how\":** While it's good to maintain mystery, a subtle hint about the map's origin or purpose would add another layer. Did the wave *bring* it, or was it *revealed* by the wave? Is it ancient, alien, or magical? Even a fleeting thought from Elias that questions its existence could propel the narrative forward and pique the reader's curiosity further.\nRefinerAgent > Elias had manned the Saltwick Head lighthouse for thirty years, his life a predictable rhythm of polishing brass and tending the lamp. He was a man of routine, not prone to flights of fancy or superstitious notions; the sea, in his experience, was a force of nature, not a mystical entity. So when a particularly vicious wave crashed against the tower, rattling the very foundations, his first thought was of structural integrity, not omens. But when the spray cleared, Elias saw it ‚Äì a rolled-up cylinder of something wedged in a crevice near the base, pulsing with an unnatural light.\n\nHe retrieved it, his gnarled fingers clumsy with a mixture of apprehension and a flicker of something he hadn't felt in decades: wonder. This was no ordinary sea-weathered parchment. It was impossibly smooth, cool to the touch, and emanated a faint, emerald luminescence. As he unfurled it, the light intensified, revealing intricate, swirling lines that coalesced into a map. Not of any coastline Elias knew, but of stars.\n\nHis breath hitched. These weren't static celestial bodies; they winked and shifted, constellations rearranging themselves in impossible configurations. Emerald light traced paths between them, forming patterns that Elias felt, deep in his bones, were significant, though he couldn't decipher their meaning. Was this a map to another world? A remnant of something ancient, or perhaps, something alien? The sheer impossibility of it sent a shiver down his spine, a primal fear warring with an unexpected, exhilarating sense of adventure. The wave hadn't just battered his lighthouse; it had delivered a mystery, a cosmic enigma that now pulsed with emerald light in his weathered hands.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\nThis notebook is for your hands-on practice and learning only.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}