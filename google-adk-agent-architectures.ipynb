{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\nIn this you will learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\nThis notebook is for your hands-on practice and learning only.","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.","metadata":{}},{"cell_type":"markdown","source":"### Section 1\n\n## ‚öôÔ∏è Setup\n\n### Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this notebook, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:28:09.650457Z","iopub.execute_input":"2025-11-10T19:28:09.650812Z","iopub.status.idle":"2025-11-10T19:28:09.731556Z","shell.execute_reply.started":"2025-11-10T19:28:09.650778Z","shell.execute_reply":"2025-11-10T19:28:09.730713Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.2 Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:28:14.994443Z","iopub.execute_input":"2025-11-10T19:28:14.994789Z","iopub.status.idle":"2025-11-10T19:29:02.103835Z","shell.execute_reply.started":"2025-11-10T19:28:14.994763Z","shell.execute_reply":"2025-11-10T19:29:02.102938Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\n### Section 2\n\n## ü§î Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:29:55.520088Z","iopub.execute_input":"2025-11-10T19:29:55.521891Z","iopub.status.idle":"2025-11-10T19:29:55.528201Z","shell.execute_reply.started":"2025-11-10T19:29:55.521840Z","shell.execute_reply":"2025-11-10T19:29:55.527289Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:30:04.280226Z","iopub.execute_input":"2025-11-10T19:30:04.280578Z","iopub.status.idle":"2025-11-10T19:30:04.287260Z","shell.execute_reply.started":"2025-11-10T19:30:04.280545Z","shell.execute_reply":"2025-11-10T19:30:04.285957Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=\"gemini-2.5-flash-lite\",\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[\n        AgentTool(research_agent),\n        AgentTool(summarizer_agent)\n    ],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:30:08.954627Z","iopub.execute_input":"2025-11-10T19:30:08.955012Z","iopub.status.idle":"2025-11-10T19:30:08.961519Z","shell.execute_reply.started":"2025-11-10T19:30:08.954984Z","shell.execute_reply":"2025-11-10T19:30:08.960482Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail in another notebook.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"What are the latest advancements in quantum computing and what do they mean for AI?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:30:46.845590Z","iopub.execute_input":"2025-11-10T19:30:46.846729Z","iopub.status.idle":"2025-11-10T19:30:54.856109Z","shell.execute_reply.started":"2025-11-10T19:30:46.846687Z","shell.execute_reply":"2025-11-10T19:30:54.854807Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Quantum AI is set to revolutionize artificial intelligence by leveraging the advanced capabilities of quantum computing. This fusion promises to overcome the limitations of classical computers, leading to faster machine learning, the ability to solve complex problems, and more efficient AI models. Key advancements include enhanced computational power through qubits, the development of Quantum Machine Learning (QML) algorithms, and improved optimization and simulation capabilities. These advancements are expected to have a significant impact across various industries, including healthcare, finance, cybersecurity, manufacturing, and scientific research. While widespread adoption is still some time away due to ongoing challenges in hardware and algorithms, the potential for a transformative shift in computational capabilities is substantial.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Section 3\n## üö• Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:06.114817Z","iopub.execute_input":"2025-11-10T19:31:06.115185Z","iopub.status.idle":"2025-11-10T19:31:06.120827Z","shell.execute_reply.started":"2025-11-10T19:31:06.115163Z","shell.execute_reply":"2025-11-10T19:31:06.119815Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\", # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:16.530341Z","iopub.execute_input":"2025-11-10T19:31:16.530659Z","iopub.status.idle":"2025-11-10T19:31:16.536701Z","shell.execute_reply.started":"2025-11-10T19:31:16.530634Z","shell.execute_reply":"2025-11-10T19:31:16.535851Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\", # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:19.814515Z","iopub.execute_input":"2025-11-10T19:31:19.814892Z","iopub.status.idle":"2025-11-10T19:31:19.821233Z","shell.execute_reply.started":"2025-11-10T19:31:19.814848Z","shell.execute_reply":"2025-11-10T19:31:19.820272Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:22.334451Z","iopub.execute_input":"2025-11-10T19:31:22.334717Z","iopub.status.idle":"2025-11-10T19:31:22.340046Z","shell.execute_reply.started":"2025-11-10T19:31:22.334699Z","shell.execute_reply":"2025-11-10T19:31:22.338756Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a blog post about the benefits of multi-agent systems for software developers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:24.984390Z","iopub.execute_input":"2025-11-10T19:31:24.984711Z","iopub.status.idle":"2025-11-10T19:31:31.553101Z","shell.execute_reply.started":"2025-11-10T19:31:24.984685Z","shell.execute_reply":"2025-11-10T19:31:31.552042Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog outline about the benefits of multi-agent systems for software developers:\n\n## Headline: **Beyond Solo Coding: Unleash Superpowers with Multi-Agent Systems**\n\n### Introduction Hook:\n\nEver felt like your software projects are a solo marathon, juggling every task yourself? Imagine a team of intelligent collaborators, each specializing in a different aspect of development, working seamlessly together to build robust, efficient, and innovative software. That's the promise of Multi-Agent Systems (MAS), and for software developers, it's a game-changer.\n\n### Main Sections:\n\n**1. Enhanced Problem-Solving and Complexity Management**\n\n*   **Divide and Conquer, Intelligently:** Break down complex problems into smaller, manageable sub-problems, each assigned to a specialized agent with the right expertise. This mirrors human expert teams, leading to more efficient and effective solutions.\n*   **Resilience and Robustness:** If one agent encounters an issue or fails, the system can often adapt and continue functioning, either through redundant agents or by re-assigning tasks. This drastically reduces single points of failure.\n*   **Emergent Behavior for Novel Solutions:** MAS can exhibit emergent behaviors ‚Äì complex, sophisticated outcomes that aren't explicitly programmed. This can lead to innovative and unexpected solutions to challenges you might not have even anticipated.\n\n**2. Improved Efficiency and Scalability**\n\n*   **Parallel Processing Power:** Agents can operate and execute tasks concurrently, significantly speeding up development cycles and runtime performance for distributed applications.\n*   **Dynamic Resource Allocation:** Agents can intelligently request and manage resources based on their current needs, leading to optimized utilization and cost savings. This is particularly valuable in cloud environments.\n*   **Seamless Scalability:** As your application grows or user demand increases, you can simply add more agents to handle the additional workload without a complete system overhaul.\n\n**3. Advanced Autonomy and Adaptability**\n\n*   **Self-Managing Systems:** Agents can monitor their own performance, identify issues, and even self-correct or adapt their behavior without constant human intervention, reducing maintenance overhead.\n*   **Learning and Evolution:** Agents can learn from their experiences and interactions, allowing the system to adapt to changing environments and improve its performance over time.\n*   **Intelligent Decision-Making:** MAS can make sophisticated decisions based on distributed information and complex reasoning, leading to more intelligent and responsive software.\n\n**4. Novel Applications and Development Paradigms**\n\n*   **Simulations and Modeling:** MAS are ideal for creating complex simulations in fields like traffic management, economics, and even biological systems, offering powerful tools for research and development.\n*   **Robotics and IoT Integration:** Agents can act as the \"brains\" for physical systems, coordinating complex actions and enabling intelligent interaction with the physical world.\n*   **Decentralized Systems and Blockchain:** The inherent distributed nature of MAS aligns perfectly with the principles of decentralized technologies, opening doors for new architectures and applications.\n\n### Concluding Thought:\n\nEmbracing multi-agent systems isn't just about adopting a new technology; it's about fundamentally rethinking how we approach software development. By leveraging the collective intelligence and specialized capabilities of these digital collaborators, developers can unlock new levels of creativity, efficiency, and resilience, building the next generation of intelligent and adaptable software solutions. It's time to step beyond the solo act and orchestrate a symphony of agents.\nWriterAgent > ## Beyond Solo Coding: Unleash Superpowers with Multi-Agent Systems\n\nEver feel like your software projects are a solo marathon, juggling every task yourself? Imagine a team of intelligent collaborators, each specializing in a different aspect of development, working seamlessly together to build robust, efficient, and innovative software. That's the promise of Multi-Agent Systems (MAS), and for software developers, it's a game-changer.\n\nMAS revolutionize how we tackle complex problems. Instead of one developer trying to master every detail, you can assign specialized agents to specific sub-problems. This \"divide and conquer\" approach, mirrored by human expert teams, leads to more effective solutions. Crucially, MAS offer enhanced resilience; if one agent falters, others can often pick up the slack, drastically reducing single points of failure. Plus, these systems can exhibit emergent behaviors ‚Äì complex, sophisticated outcomes not explicitly programmed, leading to truly novel solutions.\n\nEfficiency and scalability also get a major boost. Agents can process tasks concurrently, dramatically speeding up development and runtime performance for distributed applications. They can dynamically manage resources, optimizing utilization and saving costs, especially in cloud environments. Need to scale up? Simply add more agents ‚Äì no more complete system overhauls.\n\nBeyond that, MAS introduce advanced autonomy and adaptability. Agents can monitor themselves, identify issues, and even self-correct, significantly reducing maintenance overhead. They can learn from interactions, allowing your systems to evolve and adapt to changing environments.\n\nEmbracing MAS is about rethinking software development. By leveraging the collective intelligence of these digital collaborators, you can unlock new levels of creativity, efficiency, and resilience, building the next generation of intelligent, adaptable software. It's time to orchestrate a symphony of agents.\nEditorAgent > ## Beyond Solo Coding: Unleash Superpowers with Multi-Agent Systems\n\nEver feel like your software projects are a solo marathon, juggling every task yourself? Imagine a team of intelligent collaborators, each specializing in a different aspect of development, working seamlessly together to build robust, efficient, and innovative software. That's the promise of Multi-Agent Systems (MAS), and for software developers, it's a game-changer.\n\nMAS revolutionize how we tackle complex problems. Instead of one developer trying to master every detail, you can assign specialized agents to specific sub-problems. This \"divide and conquer\" approach, mirrored by human expert teams, leads to more effective solutions. Crucially, MAS offer enhanced resilience; if one agent falters, others can often pick up the slack, drastically reducing single points of failure. Plus, these systems can exhibit emergent behaviors ‚Äì complex, sophisticated outcomes not explicitly programmed, leading to truly novel solutions.\n\nEfficiency and scalability also get a major boost. Agents can process tasks concurrently, dramatically speeding up development and runtime performance for distributed applications. They can dynamically manage resources, optimizing utilization and saving costs, especially in cloud environments. Need to scale up? Simply add more agents ‚Äì no more complete system overhauls.\n\nBeyond that, MAS introduce advanced autonomy and adaptability. Agents can monitor themselves, identify issues, and even self-correct, significantly reducing maintenance overhead. They can learn from interactions, allowing your systems to evolve and adapt to changing environments.\n\nEmbracing MAS is about rethinking software development. By leveraging the collective intelligence of these digital collaborators, you can unlock new levels of creativity, efficiency, and resilience, building the next generation of intelligent, adaptable software. It's time to orchestrate a symphony of agents.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 4\n## üõ£Ô∏è Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:47.710025Z","iopub.execute_input":"2025-11-10T19:31:47.710470Z","iopub.status.idle":"2025-11-10T19:31:47.717830Z","shell.execute_reply.started":"2025-11-10T19:31:47.710435Z","shell.execute_reply":"2025-11-10T19:31:47.716285Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:50.469711Z","iopub.execute_input":"2025-11-10T19:31:50.470079Z","iopub.status.idle":"2025-11-10T19:31:50.475708Z","shell.execute_reply.started":"2025-11-10T19:31:50.470053Z","shell.execute_reply":"2025-11-10T19:31:50.474668Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:54.029794Z","iopub.execute_input":"2025-11-10T19:31:54.030400Z","iopub.status.idle":"2025-11-10T19:31:54.036738Z","shell.execute_reply.started":"2025-11-10T19:31:54.030372Z","shell.execute_reply":"2025-11-10T19:31:54.035625Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\", # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:31:56.656311Z","iopub.execute_input":"2025-11-10T19:31:56.657140Z","iopub.status.idle":"2025-11-10T19:31:56.663024Z","shell.execute_reply.started":"2025-11-10T19:31:56.657112Z","shell.execute_reply":"2025-11-10T19:31:56.661951Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:01.319706Z","iopub.execute_input":"2025-11-10T19:32:01.320065Z","iopub.status.idle":"2025-11-10T19:32:01.326542Z","shell.execute_reply.started":"2025-11-10T19:32:01.320038Z","shell.execute_reply":"2025-11-10T19:32:01.325452Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Run the daily executive briefing on Tech, Health, and Finance\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:06.144347Z","iopub.execute_input":"2025-11-10T19:32:06.144680Z","iopub.status.idle":"2025-11-10T19:32:12.249049Z","shell.execute_reply.started":"2025-11-10T19:32:06.144655Z","shell.execute_reply":"2025-11-10T19:32:12.248273Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > ## Daily Executive Briefing\n\n**Health:**\nGene therapy is showing remarkable promise, with recent successes in treating inherited hearing loss and sickle cell anemia. Further applications for genetic diseases, cancer, and even blindness are actively being explored. By 2024, treatments utilizing gene editing technologies like CRISPR are expected to become more widespread, offering hope for previously incurable conditions. Additionally, advances in CAR T-cell therapy are providing new avenues for brain cancer treatment.\n\n**Technology:**\nAI continues its rapid evolution, with agentic AI‚Äîsystems capable of independent task execution‚Äîpoised to reshape industries like autonomous systems and robotic process automation. Post-quantum cryptography is gaining traction as a critical defense against the threat of quantum computing to current encryption methods. Quantum computing itself is accelerating, with breakthroughs potentially impacting drug discovery, diagnostics, and cybersecurity.\n\n**Finance:**\nAI and machine learning are revolutionizing financial services by enabling near real-time, highly accurate risk decision-making and enhancing user experiences. Blockchain and decentralized finance (DeFi) are transforming traditional banking infrastructure through secure platforms for lending, credit approvals, and fraud prevention. Integration of IoT into banking offers continuous data streams for more personalized and dynamic risk assessments.\n\n**Estimated Timelines:**\n*   **Gene Therapy:** Significant clinical applications and wider accessibility are anticipated within the next 1-3 years.\n*   **Agentic AI:** Practical business applications are emerging now and are expected to expand significantly over the next 2-5 years.\n*   **Quantum Computing:** While initial breakthroughs are occurring, widespread practical impact, particularly in finance and cybersecurity, is likely 5-10 years away.\nTechResearcher > **AI/ML Trends: Key Developments and Industry Impact**\n\n**1. Generative AI for Complex Content Creation:**\nGenerative AI is expanding beyond text to create graphics, video, and music. This trend is driven by models like OpenAI's GPT and Google's Imagen, with applications in art, design, and entertainment. Companies like **Google** and **OpenAI** are at the forefront. Its potential impact lies in democratizing creative tools, personalizing content at scale, and transforming industries like marketing and media.\n\n**2. Multimodal AI:**\nThis AI type processes diverse data modalities (images, text, audio, video) simultaneously. Startups are rapidly developing and implementing multimodal AI solutions expected to be widely adopted in 2025. **Google** is a key player. The impact includes enhanced communication, more sophisticated virtual assistants, improved diagnostics in healthcare, and more intuitive user experiences across various platforms.\n\n**3. Explainable AI (XAI):**\nAs AI use grows, so does the demand for transparency and trust. XAI focuses on making AI decision-making understandable, which is crucial for regulated sectors like healthcare and finance. Companies are investing in tools and processes to mitigate bias and ensure fairness. The potential impact is increased adoption of AI in critical areas, regulatory compliance, and greater public trust in AI systems.\n\n**Main Companies Involved:**\nKey players across these trends include **Google**, **OpenAI**, **Microsoft**, **IBM**, **Nvidia**, **AMD**, and numerous startups.\n\n**Potential Impact:**\nThese AI/ML advancements promise to drive significant business growth and transformation by automating processes, enhancing decision-making, and enabling new forms of creativity. Industries like healthcare are seeing AI improve diagnostics and patient care, while finance is leveraging AI for risk management and fraud detection. Technology companies are rapidly integrating AI into their core products and services, from cloud platforms to consumer devices.\nFinanceResearcher > **Executive Briefing: November 10, 2025**\n\n**Technology:** The tech sector is seeing a surge in AI-driven energy demands, prompting companies to explore space-based data centers for constant solar power and efficient cooling. Apple is reportedly paying Google $1 billion annually to utilize its Gemini model for Siri's AI upgrade, while OpenAI is exploring consumer health tools. Tech giants like Apple and WhatsApp are vowing to alert users if their phones are targeted by government spyware.\n\n**Health:** The federal government shutdown continues to impact healthcare, with ongoing discussions about Affordable Care Act premiums. Researchers are investigating longer lifespans linked to short walks and increased health risks for veterans. Meanwhile, international health organizations are mobilizing emergency responses to public health crises, like hospital attacks in Sudan.\n\n**Finance:** Fintech is experiencing growth, with companies like SmartSearch appointing new leadership to accelerate innovation. Discussions around wealth and asset management are prominent, alongside analysis of credit builder products and housing market trends. The banking sector is navigating changing global environments, focusing on balance sheet growth and operational efficiency.\n\n**Key Fintech Trends:**\n\n1.  **Embedded Finance:** Financial services are increasingly integrated into non-financial platforms, offering seamless user experiences and expanding access.\n2.  **AI in Financial Services:** Artificial intelligence is revolutionizing areas like fraud detection, personalized customer service, and algorithmic trading.\n3.  **Decentralized Finance (DeFi):** Blockchain technology is enabling peer-to-peer financial transactions, bypassing traditional intermediaries and offering greater transparency.\n\n**Market Implications & Future Outlook:** These trends are democratizing finance, increasing efficiency, and fostering innovation. The market will likely see continued disruption of traditional institutions, a greater focus on data security and privacy, and the emergence of new business models centered around digital-first financial solutions.\nAggregatorAgent > ## Executive Summary: AI, Health, and Finance Convergence\n\nArtificial intelligence is a dominant force across technology, health, and finance, driving unprecedented innovation and transformation. In technology, generative and multimodal AI are democratizing content creation and enabling more sophisticated user experiences, while explainable AI (XAI) is crucial for building trust and ensuring ethical deployment. These advancements are directly impacting healthcare, with AI enhancing diagnostics and supporting gene therapy breakthroughs for inherited diseases and cancer. Simultaneously, AI and machine learning are revolutionizing finance by improving risk assessment, fraud detection, and customer service, with blockchain and DeFi further reshaping traditional banking.\n\nKey takeaways include the **pervasive influence of AI** across all sectors, with **multimodal AI** emerging as a critical next step for enhanced capabilities. The synergy between AI and **gene therapy** promises to unlock new treatments for previously incurable conditions. In finance, **Fintech innovation**, including embedded finance and DeFi, is poised to disrupt traditional institutions, emphasizing efficiency and data security. While quantum computing's impact is further out, its potential to transform cybersecurity and drug discovery is significant. The future points towards increasingly integrated and intelligent systems.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 5\n## ‚û∞ Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\", # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:19.881170Z","iopub.execute_input":"2025-11-10T19:32:19.881506Z","iopub.status.idle":"2025-11-10T19:32:19.887555Z","shell.execute_reply.started":"2025-11-10T19:32:19.881481Z","shell.execute_reply":"2025-11-10T19:32:19.886404Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\", # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:22.449543Z","iopub.execute_input":"2025-11-10T19:32:22.449865Z","iopub.status.idle":"2025-11-10T19:32:22.456324Z","shell.execute_reply.started":"2025-11-10T19:32:22.449841Z","shell.execute_reply":"2025-11-10T19:32:22.455212Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:26.359559Z","iopub.execute_input":"2025-11-10T19:32:26.359864Z","iopub.status.idle":"2025-11-10T19:32:26.366318Z","shell.execute_reply.started":"2025-11-10T19:32:26.359842Z","shell.execute_reply":"2025-11-10T19:32:26.365281Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    \n    output_key=\"current_story\", # It overwrites the story with the new, refined version.\n    tools=[FunctionTool(exit_loop)], # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:29.229678Z","iopub.execute_input":"2025-11-10T19:32:29.230036Z","iopub.status.idle":"2025-11-10T19:32:29.236967Z","shell.execute_reply.started":"2025-11-10T19:32:29.230013Z","shell.execute_reply":"2025-11-10T19:32:29.235746Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2, # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:32:32.389809Z","iopub.execute_input":"2025-11-10T19:32:32.390154Z","iopub.status.idle":"2025-11-10T19:32:32.395646Z","shell.execute_reply.started":"2025-11-10T19:32:32.390131Z","shell.execute_reply":"2025-11-10T19:32:32.394728Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T19:33:05.828622Z","iopub.execute_input":"2025-11-10T19:33:05.828992Z","iopub.status.idle":"2025-11-10T19:33:13.206154Z","shell.execute_reply.started":"2025-11-10T19:33:05.828966Z","shell.execute_reply":"2025-11-10T19:33:13.205158Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias, weathered as the salt-crusted stones of his lighthouse, found it wedged in a tide pool, pulsating with an eerie, internal light. It wasn't paper, nor parchment, but something supple and cool, patterned with symbols he'd never seen. As his calloused fingers traced a luminous line, the map flared, projecting a shimmering, three-dimensional image of constellations he dimly recognized, but with an unfamiliar celestial body at their heart. The light intensified, bathing the tower in an alien glow. Elias, a man who'd weathered countless storms, felt a prickle of something entirely new: wonder, tinged with a delicious fear. The sea had always held its secrets, but tonight, it offered him a glimpse of the cosmos.\nCriticAgent > This is a promising start to a story, with a strong sense of atmosphere and a compelling mystery. However, to make it even stronger, consider these suggestions:\n\n1.  **Expand on Elias's reaction and internal monologue:** While you mention \"wonder, tinged with a delicious fear,\" this could be delved into more deeply. What specific thoughts race through Elias's mind as he sees this celestial anomaly? Does he question his sanity? Does he recall old sailor's tales? Showing, not just telling, his internal experience will make him a more relatable and engaging character.\n2.  **Flesh out the description of the map:** \"Supple and cool\" and \"luminous line\" are good starting points. However, describing the texture, the material, and the nature of the \"symbols\" with more vivid imagery could enhance the mystery and otherworldliness of the object. What does \"supple and cool\" *feel* like? Are the symbols sharp, flowing, organic?\n3.  **Hint at what comes next:** The ending leaves the reader wanting more. While a cliffhanger can be effective, a slightly more concrete hint of Elias's next action or the immediate implication of the map's discovery would provide a stronger sense of narrative momentum. For example, does he try to record the anomaly, or does he feel compelled to *do* something based on what he's seen?\nRefinerAgent > Elias, weathered as the salt-crusted stones of his lighthouse, found it wedged in a tide pool, pulsating with an eerie, internal light. It wasn't paper, nor parchment, but something that felt akin to oiled silk, yet impossibly cool to the touch, like deep-sea ice. Its surface was patterned with symbols that writhed like living currents, sharp and angular in one moment, flowing and organic the next. As his calloused fingers, rough from years of rope and salt spray, traced a luminous line, the map flared. A shimmering, three-dimensional image of constellations he dimly recognized erupted into the air, dominated by an unfamiliar celestial body pulsing at their heart.\n\nThe light intensified, bathing the stone tower in an alien, ethereal glow. Elias stumbled back, his breath catching in his throat. \"Sails of the Southern Cross‚Ä¶ but that star‚Ä¶\" he whispered, his voice raspy. He gripped the rough stone wall, half-expecting to wake from a dream, or worse, a madness brought on by solitude and sea-fog. Had old Man Hemlock‚Äôs tales of sky-whales and star-born islands finally claimed his mind? The symbols on the map continued to shift, now coalescing into what looked like a trajectory, a path leading *from* that alien sun. The sea had always held its secrets, vast and unfathomable, but tonight, it had delivered a cosmic riddle. Elias, a man who'd navigated by the stars his entire life, felt a prickle of awe, a delicious fear tightening his gut. He had to record this. He had to understand. Reaching for his logbook and a stub of charcoal, his hand trembled, not from the cold, but from the momentous weight of the unknown now laid bare before him.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n### Section 6\n## Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\nThis notebook is for your hands-on practice and learning only.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)","metadata":{}}]}